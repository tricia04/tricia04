{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMumu2tMiL5u",
        "outputId": "87808fd8-747e-4955-9674-5e8e04b27f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pGici38EiN6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7332e11-d82e-47bd-adb1-b6484e204ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/newdata\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/newdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Tr8dQpNPiN2p"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from pandas import HDFStore\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, RepeatVector\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5T2Me3rRiN0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf47cd0-ebbd-4701-d34a-7023f75c80f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mod01_out02_doe05_run001.akh5',\n",
              " 'mod01_out02_doe05_run002.akh5',\n",
              " 'mod01_out02_doe05_run003.akh5',\n",
              " 'mod01_out02_doe05_run004.akh5',\n",
              " 'mod01_out02_doe05_run005.akh5',\n",
              " 'mod01_out02_doe05_run006.akh5',\n",
              " 'mod01_out02_doe05_run007.akh5',\n",
              " 'mod01_out02_doe05_run008.akh5',\n",
              " 'mod01_out02_doe05_run009 (1).akh5',\n",
              " 'mod01_out02_doe05_run010.akh5',\n",
              " 'mod01_out02_doe05_run011.akh5',\n",
              " 'mod01_out02_doe05_run012.akh5',\n",
              " 'mod01_out02_doe05_run013.akh5',\n",
              " 'mod01_out02_doe05_run014.akh5',\n",
              " 'mod01_out02_doe05_run015.akh5',\n",
              " 'mod01_out02_doe05_run016.akh5',\n",
              " 'mod01_out02_doe05_run017.akh5',\n",
              " 'mod01_out02_doe05_run018.akh5',\n",
              " 'mod01_out02_doe05_run019.akh5',\n",
              " 'mod01_out02_doe05_run020.akh5',\n",
              " 'mod01_out02_doe05_run021.akh5',\n",
              " 'mod01_out02_doe05_run022.akh5',\n",
              " 'mod01_out02_doe05_run023.akh5',\n",
              " 'mod01_out02_doe05_run024.akh5',\n",
              " 'mod01_out02_doe05_run025.akh5',\n",
              " 'mod01_out02_doe05_run026.akh5',\n",
              " 'mod01_out02_doe05_run027.akh5',\n",
              " 'mod01_out02_doe05_run028.akh5',\n",
              " 'mod01_out02_doe05_run029.akh5',\n",
              " 'mod01_out02_doe05_run030.akh5',\n",
              " 'mod01_out02_doe05_run031.akh5',\n",
              " 'mod01_out02_doe05_run032.akh5',\n",
              " 'mod01_out02_doe05_run033.akh5',\n",
              " 'mod01_out02_doe05_run034.akh5',\n",
              " 'mod01_out02_doe05_run035.akh5',\n",
              " 'mod01_out02_doe05_run036.akh5',\n",
              " 'mod01_out02_doe05_run037.akh5',\n",
              " 'mod01_out02_doe05_run038.akh5',\n",
              " 'mod01_out02_doe05_run039.akh5',\n",
              " 'mod01_out02_doe05_run040.akh5',\n",
              " 'mod01_out02_doe05_run041.akh5',\n",
              " 'mod01_out02_doe05_run042.akh5',\n",
              " 'mod01_out02_doe05_run043.akh5',\n",
              " 'mod01_out02_doe05_run044.akh5',\n",
              " 'mod01_out02_doe05_run045.akh5',\n",
              " 'mod01_out02_doe05_run046.akh5',\n",
              " 'mod01_out02_doe05_run047.akh5',\n",
              " 'mod01_out02_doe05_run048.akh5',\n",
              " 'mod01_out02_doe05_run049.akh5',\n",
              " 'mod01_out02_doe05_run050.akh5',\n",
              " 'mod01_out02_doe05_run051.akh5',\n",
              " 'mod01_out02_doe05_run052.akh5',\n",
              " 'mod01_out02_doe05_run053.akh5',\n",
              " 'mod01_out02_doe05_run054.akh5',\n",
              " 'mod01_out02_doe05_run055.akh5',\n",
              " 'mod01_out02_doe05_run056.akh5',\n",
              " 'mod01_out02_doe05_run057.akh5',\n",
              " 'mod01_out02_doe05_run058.akh5',\n",
              " 'mod01_out02_doe05_run059.akh5',\n",
              " 'mod01_out02_doe05_run060.akh5']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "directory_path = '/content/drive/MyDrive/newdata'\n",
        "file_list = os.listdir(directory_path)\n",
        "file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LgviDW7fiNxT"
      },
      "outputs": [],
      "source": [
        "def generate_data(obj):\n",
        "    mass = obj.data['mass']\n",
        "    shell_thickness = obj.data['SHELL_THICKNESS']\n",
        "    data_y = obj.data['NODE_COOR_Z']\n",
        "    y_coordinates = data_y.iloc[:1, :]\n",
        "    output_sequence = data_y.diff(axis=0).iloc[1:, :]\n",
        "    return mass, shell_thickness, y_coordinates, output_sequence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m9fb-50JiNu7"
      },
      "outputs": [],
      "source": [
        "def preprocess_feature_engineering(mass, shell_thickness, y_coordinates, output_sequence):\n",
        "\n",
        "    scaler_mass = StandardScaler()\n",
        "    scaler_shell_thickness = StandardScaler()\n",
        "    scaler_y_coordinates = StandardScaler()\n",
        "\n",
        "    mass_scaled = scaler_mass.fit_transform(mass.values.reshape(-1, 1))\n",
        "    shell_thickness_scaled = scaler_shell_thickness.fit_transform(shell_thickness.values.reshape(-1, 1))\n",
        "    y_coordinates_scaled = scaler_y_coordinates.fit_transform(y_coordinates)\n",
        "\n",
        "\n",
        "    scaler_minmax = MinMaxScaler()\n",
        "    y_coordinates_minmax = scaler_minmax.fit_transform(y_coordinates)\n",
        "\n",
        "\n",
        "\n",
        "    return mass_scaled, shell_thickness_scaled, y_coordinates_scaled, output_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CM5psjQ_iNsc"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import Series as Ds\n",
        "from pandas import DataFrame as Df\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "\n",
        "def make_submission_folder(submission_template_folder=None, model_name=None):\n",
        "\n",
        "    src = str(submission_template_folder)\n",
        "    dst = Path(src).parent.joinpath(model_name)\n",
        "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "class AkH5file():\n",
        "    ''' AKH5 file is a hdf5 file containing node coordinates,\n",
        "    element connectivities and attributes as function of time.\n",
        "    This class provides methods to read and update coordinates of the file.\n",
        "    '''\n",
        "    _fig_height = 400\n",
        "    _fig_width  = 400\n",
        "\n",
        "\n",
        "    def __init__(self,file_path) -> None:\n",
        "        self.root_name = 'All_Nodes'\n",
        "        self.file_path = file_path\n",
        "        self.file_name = Path(file_path).name\n",
        "\n",
        "        self._open_file()\n",
        "        self._read_all_datasets()\n",
        "        self._close_file()\n",
        "\n",
        "\n",
        "    def _open_file(self,mode='r'):\n",
        "        self._h5file = h5py.File(self.file_path, mode=mode)\n",
        "        self._root   = self._h5file[self.root_name]\n",
        "\n",
        "\n",
        "    def _close_file(self):\n",
        "        self._h5file.close()\n",
        "\n",
        "\n",
        "    def _read_all_datasets(self):\n",
        "        ''' Reading all data sets contained under All_Nodes group'''\n",
        "        dataset_names = list(self._h5file[self.root_name].keys())\n",
        "        self.data={}\n",
        "        for name in dataset_names:\n",
        "            self.data[name]=Df(self._root[name])\n",
        "\n",
        "\n",
        "    @property\n",
        "    def summary(self):\n",
        "        summary = Ds(dtype=object)\n",
        "        for name, dset in self.data.items():\n",
        "            summary[name] = dset.shape\n",
        "        return summary\n",
        "\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        repr = self.summary.to_string()\n",
        "        return repr\n",
        "\n",
        "\n",
        "    def write_node_coords(self, coords_X=None , coords_Y=None, coords_Z=None):\n",
        "        ''' Updates NODE_COOR_X Y and Z tables in ahh5 file.\n",
        "        Inputs coords_x y z shape should be (n_time * n_nodes)\n",
        "        '''\n",
        "        self._open_file(mode='r+')\n",
        "        # opts={'compression':'gzip','compression_opts':0}\n",
        "        opts ={}\n",
        "\n",
        "        del self._root['TIME']\n",
        "        self._root.create_dataset(name='TIME',data=np.arange(0,82.5,2.5),**opts) # Writing in h5 file\n",
        "        self.data['TIME']  = Df(np.arange(0,82.5,2.5)) # Just to keep data field in sync\n",
        "\n",
        "        del self._root['NODE_COOR_X']\n",
        "        self._root.create_dataset(name='NODE_COOR_X',data=coords_X,**opts) # Writing in h5 file\n",
        "        self.data['NODE_COOR_X']  = Df(coords_X) # Just to keep data field in sync\n",
        "\n",
        "        del self._root['NODE_COOR_Y']\n",
        "        self._root.create_dataset(name='NODE_COOR_Y',data=coords_Y ,**opts) # Writing in h5 file\n",
        "        self.data['NODE_COOR_Y']  = Df(coords_Y) # Just to keep data field in sync\n",
        "\n",
        "        del self._root['NODE_COOR_Z']\n",
        "        self._root.create_dataset(name='NODE_COOR_Z',data=coords_Z,**opts) # Writing in h5 file\n",
        "        self.data['NODE_COOR_Z']  = Df(coords_Z) # Just to keep data field in sync\n",
        "\n",
        "        self._close_file()\n",
        "\n",
        "\n",
        "    def get_signal_rel_dist_nodes(self,node_id,node_id_ref,remove_offset=False):\n",
        "        ''' Returns distance between nodes as function of time '''\n",
        "        idx_nod = (self.data['DEFNODE']==node_id).values.ravel()\n",
        "        idx_ref = (self.data['DEFNODE']==node_id_ref).values.ravel()\n",
        "\n",
        "        X_nod = self.data['NODE_COOR_X'].values[:,idx_nod].ravel()\n",
        "        Y_nod = self.data['NODE_COOR_Y'].values[:,idx_nod].ravel()\n",
        "        Z_nod = self.data['NODE_COOR_Z'].values[:,idx_nod].ravel()\n",
        "\n",
        "        X_ref = self.data['NODE_COOR_X'].values[:,idx_ref].ravel()\n",
        "        Y_ref = self.data['NODE_COOR_Y'].values[:,idx_ref].ravel()\n",
        "        Z_ref = self.data['NODE_COOR_Z'].values[:,idx_ref].ravel()\n",
        "\n",
        "        X_vec = X_nod - X_ref\n",
        "        Y_vec = Y_nod - Y_ref\n",
        "        Z_vec = Z_nod - Z_ref\n",
        "        res = (X_vec**2 + Y_vec**2 + Z_vec**2 )**.5\n",
        "        if remove_offset:\n",
        "            res = res - res[0]\n",
        "        return res\n",
        "\n",
        "\n",
        "    def plot3d(self,time=0):\n",
        "        ''' Plots 3d node positions at a given time.\n",
        "        The closest time is used for display\n",
        "        '''\n",
        "        # Display options\n",
        "        opts_markers = dict(mode='markers', marker_symbol='square', marker_size=2, opacity=0.2, marker_color='green')\n",
        "        opts_axis   = dict(showgrid=False, title='',showline=False,zeroline=False,ticks = '',\n",
        "                           showticklabels = False, autorange=True)\n",
        "\n",
        "        times_all    = self.data['TIME'].copy()\n",
        "        times_all.columns = ['time']\n",
        "        time_closest = self._filter_closest_df(times_all,'time',time)['time']\n",
        "        time_index   = time_closest.index[0]\n",
        "\n",
        "        x = self.data['NODE_COOR_X'].loc[time_index,:]\n",
        "        y = self.data['NODE_COOR_Y'].loc[time_index,:]\n",
        "        z = self.data['NODE_COOR_Z'].loc[time_index,:]\n",
        "\n",
        "        # Mapping node id to index\n",
        "        self.map_idx_uid_nodes = self.data['DEFNODE'].to_dict()[0]\n",
        "        self.map_uid_idx_nodes = {v:k for k,v in self.map_idx_uid_nodes.items()}\n",
        "\n",
        "        conn1 = self.data['SHELL2NODE'].iloc[:,[1,2,3]].applymap(lambda x: self.map_uid_idx_nodes[x])\n",
        "        conn2 = self.data['SHELL2NODE'].iloc[:,[3,4,1]].applymap(lambda x: self.map_uid_idx_nodes[x])\n",
        "        conn2.columns = conn1.columns\n",
        "        conn = pd.concat([conn1,conn2])\n",
        "\n",
        "        i= conn.iloc[:,0]\n",
        "        j= conn.iloc[:,1]\n",
        "        k= conn.iloc[:,2]\n",
        "\n",
        "        geom = go.Mesh3d( x=x, y=y, z=z,  i=i, j=j, k=k,opacity=0.3)\n",
        "        fig  = go.Figure(data=[geom])\n",
        "\n",
        "        fig.update_scenes(aspectmode='data', xaxis=opts_axis, yaxis=opts_axis, zaxis=opts_axis)\n",
        "        fig.update_layout({'scene':{\"camera\": {\"projection\":{\"type\": \"orthographic\"}}}})\n",
        "                                                # {\"type\": \"orthographic\"}}}})\n",
        "        fig.update_layout(height=self._fig_height, width=self._fig_width, margin=dict(l=0, r=0, t=35, b=0),\n",
        "                          title=f'{self.file_name} : {time} ms')\n",
        "        fig.update_layout(scene_camera=dict(eye=dict(x=2.5, y=0, z=0)))\n",
        "\n",
        "        return fig\n",
        "\n",
        "\n",
        "    def plot3danim(self,times=(0,200),skip=1):\n",
        "        ''' Plots 3d animated mmesh.\n",
        "        '''\n",
        "        # Time frames to display\n",
        "        time_values = self.data['TIME'].copy()\n",
        "        time_values.columns=['time']\n",
        "        time_values = time_values.query('@times[0] <= time <= @times[1]')['time'].values[::skip]\n",
        "\n",
        "        # Spatial ranges\n",
        "        x_range = [self.data['NODE_COOR_X'].min().min(),self.data['NODE_COOR_X'].max().max()]\n",
        "        y_range = [self.data['NODE_COOR_Y'].min().min(),self.data['NODE_COOR_Y'].max().max()]\n",
        "        z_range = [self.data['NODE_COOR_Z'].min().min(),self.data['NODE_COOR_Z'].max().max()]\n",
        "\n",
        "        # Creating figure and frames\n",
        "        fig  = go.Figure( data   = [self.plot3d(time=time_values[0]).data[0]],\n",
        "                          frames = [go.Frame(data=[self.plot3d(time=t).data[0]],\n",
        "                                    name=f'time{t:.2f}') for t in time_values])\n",
        "\n",
        "        # Customise figure aspect\n",
        "        opts_axis   = dict(showgrid=False, title='',showline=False,zeroline=False,ticks = '',\n",
        "                           showticklabels = False, autorange=False)\n",
        "        opts_axis_x = dict(range=x_range) | opts_axis\n",
        "        opts_axis_y = dict(range=y_range) | opts_axis\n",
        "        opts_axis_z = dict(range=z_range) | opts_axis\n",
        "\n",
        "        fig.update_scenes(aspectmode='data', xaxis=opts_axis_x, yaxis=opts_axis_y, zaxis=opts_axis_z)\n",
        "        fig.update_layout(height=self._fig_height, width=self._fig_width, margin=dict(l=0, r=0, t=35, b=0))\n",
        "        fig.update_layout({'scene':{\"camera\": {\"projection\": {\"type\": \"orthographic\"}}}})\n",
        "        fig.update_layout(scene_camera=dict(eye=dict(x=2.5, y=0, z=0)))\n",
        "\n",
        "        # Create animation control\n",
        "        fig.update_layout(updatemenus=[dict(type=\"buttons\",\n",
        "            buttons=[dict(label=\"Play\",method=\"animate\",\n",
        "                    args=[None, {\"frame\": {\"duration\": 1, \"redraw\": True},\n",
        "                    \"fromcurrent\": True, \"transition\": {\"duration\": 0}}])])])\n",
        "\n",
        "        return fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Helper functions --------------------------\n",
        "\n",
        "    @staticmethod\n",
        "    def _filter_closest_df(df,filtering_column,target_value):\n",
        "        ''' Helper function to select dataframe rows where the filtering_column value is the closest to the target value'''\n",
        "        closest_value = df.iloc[(df[filtering_column]-target_value).abs().argsort()[:1]][filtering_column].values[0]\n",
        "        df_selection  = df[df[filtering_column]==closest_value]\n",
        "        return df_selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O02McAgliNp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3908c91-36ad-430c-8f50-6a7ffba2c2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mod01_out02_doe05_run001.akh5\n",
            "mod01_out02_doe05_run002.akh5\n",
            "mod01_out02_doe05_run003.akh5\n",
            "mod01_out02_doe05_run004.akh5\n",
            "mod01_out02_doe05_run005.akh5\n",
            "mod01_out02_doe05_run006.akh5\n",
            "mod01_out02_doe05_run007.akh5\n",
            "mod01_out02_doe05_run008.akh5\n",
            "mod01_out02_doe05_run009 (1).akh5\n",
            "mod01_out02_doe05_run010.akh5\n",
            "mod01_out02_doe05_run011.akh5\n",
            "mod01_out02_doe05_run012.akh5\n",
            "mod01_out02_doe05_run013.akh5\n",
            "mod01_out02_doe05_run014.akh5\n",
            "mod01_out02_doe05_run015.akh5\n",
            "mod01_out02_doe05_run016.akh5\n",
            "mod01_out02_doe05_run017.akh5\n",
            "mod01_out02_doe05_run018.akh5\n",
            "mod01_out02_doe05_run019.akh5\n",
            "mod01_out02_doe05_run020.akh5\n",
            "mod01_out02_doe05_run021.akh5\n",
            "mod01_out02_doe05_run022.akh5\n",
            "mod01_out02_doe05_run023.akh5\n",
            "mod01_out02_doe05_run024.akh5\n",
            "mod01_out02_doe05_run025.akh5\n",
            "mod01_out02_doe05_run026.akh5\n",
            "mod01_out02_doe05_run027.akh5\n",
            "mod01_out02_doe05_run028.akh5\n",
            "mod01_out02_doe05_run029.akh5\n",
            "mod01_out02_doe05_run030.akh5\n",
            "mod01_out02_doe05_run031.akh5\n",
            "mod01_out02_doe05_run032.akh5\n",
            "mod01_out02_doe05_run033.akh5\n",
            "mod01_out02_doe05_run034.akh5\n",
            "mod01_out02_doe05_run035.akh5\n",
            "mod01_out02_doe05_run036.akh5\n",
            "mod01_out02_doe05_run037.akh5\n",
            "mod01_out02_doe05_run038.akh5\n",
            "mod01_out02_doe05_run039.akh5\n",
            "mod01_out02_doe05_run040.akh5\n",
            "mod01_out02_doe05_run041.akh5\n",
            "mod01_out02_doe05_run042.akh5\n",
            "mod01_out02_doe05_run043.akh5\n",
            "mod01_out02_doe05_run044.akh5\n",
            "mod01_out02_doe05_run045.akh5\n",
            "mod01_out02_doe05_run046.akh5\n",
            "mod01_out02_doe05_run047.akh5\n",
            "mod01_out02_doe05_run048.akh5\n",
            "mod01_out02_doe05_run049.akh5\n",
            "mod01_out02_doe05_run050.akh5\n",
            "mod01_out02_doe05_run051.akh5\n",
            "mod01_out02_doe05_run052.akh5\n",
            "mod01_out02_doe05_run053.akh5\n",
            "mod01_out02_doe05_run054.akh5\n",
            "mod01_out02_doe05_run055.akh5\n",
            "mod01_out02_doe05_run056.akh5\n",
            "mod01_out02_doe05_run057.akh5\n",
            "mod01_out02_doe05_run058.akh5\n",
            "mod01_out02_doe05_run059.akh5\n",
            "mod01_out02_doe05_run060.akh5\n"
          ]
        }
      ],
      "source": [
        "for afile in file_list:\n",
        "    print(afile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pltqIiMqiNni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4b202a-28cd-40af-a265-7b12b585c433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Datasets:   2%|▏         | 1/60 [00:01<01:23,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:   3%|▎         | 2/60 [00:03<01:33,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:   5%|▌         | 3/60 [00:05<01:45,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:   7%|▋         | 4/60 [00:07<01:54,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:   8%|▊         | 5/60 [00:09<01:46,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  10%|█         | 6/60 [00:10<01:34,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  12%|█▏        | 7/60 [00:17<02:50,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  13%|█▎        | 8/60 [00:18<02:25,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  15%|█▌        | 9/60 [00:20<02:10,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  17%|█▋        | 10/60 [00:22<01:53,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  18%|█▊        | 11/60 [00:23<01:38,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  20%|██        | 12/60 [00:25<01:26,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  22%|██▏       | 13/60 [00:27<01:22,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  23%|██▎       | 14/60 [00:28<01:19,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  25%|██▌       | 15/60 [00:30<01:13,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  27%|██▋       | 16/60 [00:32<01:22,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  28%|██▊       | 17/60 [00:34<01:19,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  30%|███       | 18/60 [00:36<01:17,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  32%|███▏      | 19/60 [00:37<01:12,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  33%|███▎      | 20/60 [00:39<01:06,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  35%|███▌      | 21/60 [00:42<01:29,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  37%|███▋      | 22/60 [00:44<01:17,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  38%|███▊      | 23/60 [00:46<01:12,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  40%|████      | 24/60 [00:47<01:09,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  42%|████▏     | 25/60 [00:49<01:03,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  43%|████▎     | 26/60 [00:50<00:57,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  45%|████▌     | 27/60 [00:52<00:57,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  47%|████▋     | 28/60 [00:54<00:53,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  48%|████▊     | 29/60 [00:55<00:49,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  50%|█████     | 30/60 [00:57<00:47,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  52%|█████▏    | 31/60 [00:58<00:44,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  53%|█████▎    | 32/60 [01:00<00:46,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  55%|█████▌    | 33/60 [01:02<00:44,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  57%|█████▋    | 34/60 [01:03<00:41,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  58%|█████▊    | 35/60 [01:05<00:39,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  60%|██████    | 36/60 [01:06<00:35,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  62%|██████▏   | 37/60 [01:08<00:34,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  63%|██████▎   | 38/60 [01:09<00:32,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  65%|██████▌   | 39/60 [01:10<00:30,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  67%|██████▋   | 40/60 [01:16<00:52,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  68%|██████▊   | 41/60 [01:17<00:43,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  70%|███████   | 42/60 [01:19<00:36,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  72%|███████▏  | 43/60 [01:20<00:31,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  73%|███████▎  | 44/60 [01:22<00:28,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  75%|███████▌  | 45/60 [01:23<00:24,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  77%|███████▋  | 46/60 [01:28<00:37,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  78%|███████▊  | 47/60 [01:30<00:30,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  80%|████████  | 48/60 [01:31<00:24,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  82%|████████▏ | 49/60 [01:32<00:20,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  83%|████████▎ | 50/60 [01:34<00:17,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  85%|████████▌ | 51/60 [01:35<00:14,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  87%|████████▋ | 52/60 [01:37<00:12,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  88%|████████▊ | 53/60 [01:39<00:12,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  90%|█████████ | 54/60 [01:41<00:10,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  92%|█████████▏| 55/60 [01:42<00:08,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  93%|█████████▎| 56/60 [01:44<00:06,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  95%|█████████▌| 57/60 [01:45<00:04,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  97%|█████████▋| 58/60 [01:47<00:03,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Datasets:  98%|█████████▊| 59/60 [01:48<00:01,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Datasets: 100%|██████████| 60/60 [01:50<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15718 15718 15718 15718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_array(arr, target_length):\n",
        "    if len(arr) < target_length:\n",
        "        return np.pad(arr, (0, target_length - len(arr)), constant_values=0)\n",
        "    elif len(arr) > target_length:\n",
        "        return arr[:target_length]\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "processed_dataframes = []\n",
        "\n",
        "for afile in tqdm(file_list, desc=\"Processing Datasets\"):\n",
        "    obj = AkH5file(afile)\n",
        "    mass, shell_thickness, y_coordinates, output_sequence = generate_data(obj)\n",
        "\n",
        "\n",
        "    mass_scaled, shell_thickness_scaled, y_coordinates_scaled, output_sequence = \\\n",
        "        preprocess_feature_engineering(mass, shell_thickness, y_coordinates, output_sequence)\n",
        "\n",
        "\n",
        "    max_length = max(len(arr) for arr in [mass_scaled, shell_thickness_scaled, y_coordinates_scaled, output_sequence.values])\n",
        "\n",
        "\n",
        "    mass_scaled = pad_array(mass_scaled.flatten(), max_length)\n",
        "    shell_thickness_scaled = pad_array(shell_thickness_scaled.flatten(), max_length)\n",
        "    y_coordinates_scaled = pad_array(y_coordinates_scaled.flatten(), max_length)\n",
        "    output_sequence = pad_array(output_sequence.values.flatten(), max_length)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'mass_scaled': mass_scaled,\n",
        "        'shell_thickness_scaled': shell_thickness_scaled,\n",
        "        'y_coordinates_scaled': y_coordinates_scaled,\n",
        "        'output_sequence': output_sequence,\n",
        "\n",
        "    })\n",
        "\n",
        "    processed_dataframes.append(df)\n",
        "\n",
        "\n",
        "    print(len(mass_scaled), len(shell_thickness_scaled), len(y_coordinates_scaled), len(output_sequence))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU5F4v78iNk9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
        "\n",
        "\n",
        "X_train_list = []\n",
        "y_train_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GdfWL1wiNjK"
      },
      "outputs": [],
      "source": [
        "max_length = max(len(df) for df in processed_dataframes)\n",
        "\n",
        "\n",
        "for df in processed_dataframes:\n",
        "    df_padded = df.copy()\n",
        "    for col in df.columns:\n",
        "        df_padded[col] = np.pad(df[col].values, (0, max_length - len(df[col])), constant_values=0)\n",
        "\n",
        "    X_train_list.append(df_padded[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']])\n",
        "    y_train_list.append(df_padded['output_sequence'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OfjXHbwiNgK"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([X.values for X in X_train_list])\n",
        "y_train = np.array([y.values for y in y_train_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlmhFMsaiNdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f29a3fa-ff7b-414a-c448-b294e2e1bf15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07568741, -0.05715084, -0.05715048, ...,  0.87127686,\n",
              "         1.2034302 ,  1.4001465 ],\n",
              "       [-0.11901188, -0.10325432, -0.10325468, ...,  0.62213135,\n",
              "         1.02771   ,  1.2298584 ],\n",
              "       [-0.08788395, -0.07227612, -0.07227612, ...,  0.5354614 ,\n",
              "         0.76068115,  0.93078613],\n",
              "       ...,\n",
              "       [-0.07354832, -0.05494118, -0.05494106, ...,  0.79455566,\n",
              "         1.0390015 ,  1.1972046 ],\n",
              "       [-0.09612083, -0.07766151, -0.07766187, ...,  0.9920044 ,\n",
              "         1.3783569 ,  1.5652466 ],\n",
              "       [-0.09513283, -0.07666206, -0.07666254, ...,  0.95635986,\n",
              "         1.2802734 ,  1.4658813 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrBu5qMDiyWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ca9da0-ea9d-4d6e-cb0b-3519c7a05bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100:\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Discriminator Loss: 0.25961408019065857, Generator Loss: 0.11466202884912491\n",
            "Epoch 2/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.40659254789352417, Generator Loss: 0.02945793606340885\n",
            "Epoch 3/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Discriminator Loss: 0.45734113454818726, Generator Loss: 0.008169583044946194\n",
            "Epoch 4/100:\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4602012634277344, Generator Loss: 0.008130321279168129\n",
            "Epoch 5/100:\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Discriminator Loss: 0.460366815328598, Generator Loss: 0.006932151969522238\n",
            "Epoch 6/100:\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4696977734565735, Generator Loss: 0.009964671917259693\n",
            "Epoch 7/100:\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Discriminator Loss: 0.48271188139915466, Generator Loss: 0.003977140877395868\n",
            "Epoch 8/100:\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Discriminator Loss: 0.48632144927978516, Generator Loss: 0.002307899296283722\n",
            "Epoch 9/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Discriminator Loss: 0.48233795166015625, Generator Loss: 0.0036666966043412685\n",
            "Epoch 10/100:\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.48706358671188354, Generator Loss: 0.0037481579929590225\n",
            "Epoch 11/100:\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.49212998151779175, Generator Loss: 0.003938969224691391\n",
            "Epoch 12/100:\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.49482592940330505, Generator Loss: 0.0007137800566852093\n",
            "Epoch 13/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Discriminator Loss: 0.49667254090309143, Generator Loss: 0.00047268258640542626\n",
            "Epoch 14/100:\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.4942086338996887, Generator Loss: 0.0010760525474324822\n",
            "Epoch 15/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.49878939986228943, Generator Loss: 0.000626798311714083\n",
            "Epoch 16/100:\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4993661046028137, Generator Loss: 9.86771919997409e-06\n",
            "Epoch 17/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Discriminator Loss: 0.4993855357170105, Generator Loss: 1.1085887308581732e-05\n",
            "Epoch 18/100:\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.48969197273254395, Generator Loss: 0.004468865226954222\n",
            "Epoch 19/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Discriminator Loss: 0.49985799193382263, Generator Loss: 3.098072340890212e-07\n",
            "Epoch 20/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Discriminator Loss: 0.49999552965164185, Generator Loss: 2.1406662553680178e-10\n",
            "Epoch 21/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.499999463558197, Generator Loss: 8.237677033562374e-12\n",
            "Epoch 22/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 1.3500311810035314e-14\n",
            "Epoch 23/100:\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 5.169198402654729e-13\n",
            "Epoch 24/100:\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 1.0480505352461478e-13\n",
            "Epoch 25/100:\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 2.7782219884017745e-13\n",
            "Epoch 26/100:\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 5.364597790514028e-14\n",
            "Epoch 27/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.49999943375587463, Generator Loss: 9.289990651750735e-12\n",
            "Epoch 28/100:\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 3.481659472987127e-14\n",
            "Epoch 29/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.49999967217445374, Generator Loss: 3.55271373174006e-16\n",
            "Epoch 30/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 2.3447909941270127e-14\n",
            "Epoch 31/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 7.894129685874496e-13\n",
            "Epoch 32/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 3.7658766350538025e-14\n",
            "Epoch 33/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 3.335998198603779e-13\n",
            "Epoch 34/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 5.787370365925582e-13\n",
            "Epoch 35/100:\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 1.4921396773335746e-14\n",
            "Epoch 36/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 2.842170985392048e-15\n",
            "Epoch 37/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 3.623767884613875e-14\n",
            "Epoch 38/100:\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 1.9895196262469626e-14\n",
            "Epoch 39/100:\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 8.348877145181177e-14\n",
            "Epoch 40/100:\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 7.460698725481052e-14\n",
            "Epoch 41/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 4.4266811895753155e-13\n",
            "Epoch 42/100:\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 6.750155989720952e-14\n",
            "Epoch 43/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Discriminator Loss: 0.4999990463256836, Generator Loss: 8.881784197001252e-15\n",
            "Epoch 44/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 8.3133498728679e-14\n",
            "Epoch 45/100:\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Discriminator Loss: 0.4999995827674866, Generator Loss: 2.1671553101869877e-14\n",
            "Epoch 46/100:\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 1.4210854715202004e-14\n",
            "Epoch 47/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 1.2434497875801753e-14\n",
            "Epoch 48/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 3.552713678800501e-15\n",
            "Epoch 49/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 3.55271373174006e-16\n",
            "Epoch 50/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 2.4513724722536635e-14\n",
            "Epoch 51/100:\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4999992251396179, Generator Loss: 1.1191048088221578e-13\n",
            "Epoch 52/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 8.526513167934381e-15\n",
            "Epoch 53/100:\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Discriminator Loss: 0.4999995827674866, Generator Loss: 5.82645029770755e-14\n",
            "Epoch 54/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 5.329070518200751e-15\n",
            "Epoch 55/100:\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 1.7408297364935633e-14\n",
            "Epoch 56/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 3.55271373174006e-16\n",
            "Epoch 57/100:\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 5.684341970784096e-15\n",
            "Epoch 58/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Discriminator Loss: 0.49999961256980896, Generator Loss: 8.994760665459456e-12\n",
            "Epoch 59/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999995827674866, Generator Loss: 4.4018123022439293e-13\n",
            "Epoch 60/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 3.142375248899043e-12\n",
            "Epoch 61/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 2.4868995328087033e-15\n",
            "Epoch 62/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Discriminator Loss: 0.4999995231628418, Generator Loss: 1.5702994731348757e-13\n",
            "Epoch 63/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999987483024597, Generator Loss: 9.201528292568026e-14\n",
            "Epoch 64/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 2.4158453693469764e-14\n",
            "Epoch 65/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 7.460698386667873e-15\n",
            "Epoch 66/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 9.237055226068124e-15\n",
            "Epoch 67/100:\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 4.5830005101273746e-14\n",
            "Epoch 68/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999985098838806, Generator Loss: 7.10542746348012e-16\n",
            "Epoch 69/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 1.2079226846734882e-14\n",
            "Epoch 70/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 6.969003065598889e-12\n",
            "Epoch 71/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 4.9737990656174066e-15\n",
            "Epoch 72/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 3.18323140199514e-13\n",
            "Epoch 73/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999967217445374, Generator Loss: 2.7689851279932842e-12\n",
            "Epoch 74/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 5.080380628447352e-14\n",
            "Epoch 75/100:\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 4.9737990656174066e-15\n",
            "Epoch 76/100:\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 4.3343106203739754e-14\n",
            "Epoch 77/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Discriminator Loss: 0.49999961256980896, Generator Loss: 1.0302870007334632e-14\n",
            "Epoch 78/100:\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 4.9737990656174066e-15\n",
            "Epoch 79/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 1.3500311810035314e-14\n",
            "Epoch 80/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.49999985098838806, Generator Loss: 9.221423971639275e-12\n",
            "Epoch 81/100:\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 1.1546319456101628e-13\n",
            "Epoch 82/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 3.5171864064872244e-14\n",
            "Epoch 83/100:\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.49999943375587463, Generator Loss: 4.5535129486462544e-12\n",
            "Epoch 84/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 9.450218521134604e-14\n",
            "Epoch 85/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 2.2382096854069514e-14\n",
            "Epoch 86/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Discriminator Loss: 0.5, Generator Loss: 5.684341970784096e-15\n",
            "Epoch 87/100:\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.49999770522117615, Generator Loss: 9.1294081669413e-12\n",
            "Epoch 88/100:\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Discriminator Loss: 0.4999997019767761, Generator Loss: 3.2756019034338446e-13\n",
            "Epoch 89/100:\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 1.8829383175269013e-14\n",
            "Epoch 90/100:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 1.5681322559912836e-11\n",
            "Epoch 91/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.4999999403953552, Generator Loss: 3.552713678800501e-15\n",
            "Epoch 92/100:\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 9.414691248821327e-14\n",
            "Epoch 93/100:\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Discriminator Loss: 0.4999997019767761, Generator Loss: 2.842170985392048e-15\n",
            "Epoch 94/100:\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Discriminator Loss: 0.4999997615814209, Generator Loss: 7.027267765087608e-13\n",
            "Epoch 95/100:\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Discriminator Loss: 0.49999961256980896, Generator Loss: 7.034372812974449e-14\n",
            "Epoch 96/100:\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 5.435651996327402e-14\n",
            "Epoch 97/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Discriminator Loss: 0.4999992847442627, Generator Loss: 5.851319320564208e-13\n",
            "Epoch 98/100:\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Discriminator Loss: 0.4999995827674866, Generator Loss: 2.4229506205217244e-13\n",
            "Epoch 99/100:\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Discriminator Loss: 0.4999998211860657, Generator Loss: 3.616662633439127e-13\n",
            "Epoch 100/100:\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Discriminator Loss: 0.49999991059303284, Generator Loss: 4.0643045027578817e-13\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Define or import processed_dataframes, X_train_list, y_train_list, max_length\n",
        "\n",
        "# Reshape and pad the data\n",
        "X_train_padded = []\n",
        "max_length = max(len(df) for df in processed_dataframes)\n",
        "\n",
        "for df in processed_dataframes:\n",
        "    df_padded = df.copy()\n",
        "    for col in df.columns:\n",
        "        df_padded[col] = np.pad(df[col].values, (0, max_length - len(df[col])), constant_values=0)\n",
        "\n",
        "    X_train_padded.append(df_padded[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']])\n",
        "\n",
        "X_train_padded = np.array([X.values for X in X_train_padded])\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "epochs = 100  # Change the number of epochs as needed\n",
        "batch_size = 10\n",
        "\n",
        "# Generator\n",
        "latent_dim = 100\n",
        "generator_input = Input(shape=(latent_dim,))\n",
        "x = Dense(128, activation='relu')(generator_input)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "generator_output = Dense(max_length * X_train_padded.shape[2], activation='linear')(x)\n",
        "generator_output = Reshape((max_length, X_train_padded.shape[2]))(generator_output)\n",
        "generator = Model(generator_input, generator_output)\n",
        "\n",
        "# Discriminator\n",
        "discriminator_input = Input(shape=(max_length, X_train_padded.shape[2]))\n",
        "x = Flatten()(discriminator_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "discriminator_output = Dense(1, activation='sigmoid')(x)\n",
        "discriminator = Model(discriminator_input, discriminator_output)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='mse')  # Change loss to 'mse'\n",
        "\n",
        "# Combined Model (GAN)\n",
        "gan_input = Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='mse')  # Change loss to 'mse'\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}:')\n",
        "    for i in range(0, len(X_train_padded), batch_size):\n",
        "        X_train_batch = X_train_padded[i:i+batch_size]\n",
        "\n",
        "        # Sample random noise as input to the generator\n",
        "        noise = np.random.normal(0, 1, (len(X_train_batch), latent_dim))\n",
        "\n",
        "        # Generate a batch of new sequences\n",
        "        generated_sequences = generator.predict(noise)\n",
        "\n",
        "        # Reshape X_train_batch to match the shape of generated_sequences\n",
        "        X_train_batch_reshaped = X_train_batch.reshape(-1, max_length, X_train_padded.shape[2])\n",
        "\n",
        "        # Combine generated sequences with real sequences\n",
        "        X_combined = np.concatenate([X_train_batch_reshaped, generated_sequences])\n",
        "        y_combined = np.concatenate([np.ones((len(X_train_batch_reshaped), 1)), np.zeros((len(generated_sequences), 1))])\n",
        "\n",
        "        # Train discriminator\n",
        "        d_loss = discriminator.train_on_batch(X_combined, y_combined)\n",
        "\n",
        "        # Train generator (via GAN)\n",
        "        noise = np.random.normal(0, 1, (len(X_train_batch_reshaped), latent_dim))\n",
        "        y_gan = np.ones((len(X_train_batch_reshaped), 1))\n",
        "        g_loss = gan.train_on_batch(noise, y_gan)\n",
        "\n",
        "    # Print progress after each epoch\n",
        "    print(f'Discriminator Loss: {d_loss}, Generator Loss: {g_loss}')\n",
        "\n",
        "    # Clear session to release memory\n",
        "    K.clear_session()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxsHrf9PwKDm",
        "outputId": "6d499e1f-18ed-445e-c463-64dec277a9b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEYayg6owPpI",
        "outputId": "a3f5c719-05cc-45c8-f318-35332247bad0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->Tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->Tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->Tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->Tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->Tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->Tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->Tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->Tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->Tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->Tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->Tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->Tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->Tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import mse\n",
        "import numpy as np\n",
        "\n",
        "# Define or import processed_dataframes, X_train_list, y_train_list, max_length\n",
        "max_length = max(len(df) for df in processed_dataframes)\n",
        "\n",
        "# Reshape and pad the data\n",
        "X_train_padded = []\n",
        "for df in processed_dataframes:\n",
        "    df_padded = df.copy()\n",
        "    for col in df.columns:\n",
        "        df_padded[col] = np.pad(df[col].values, (0, max_length - len(df[col])), constant_values=0)\n",
        "    X_train_padded.append(df_padded[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']])\n",
        "\n",
        "X_train_padded = np.array([X.values for X in X_train_padded])\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "epochs = 100  # Change the number of epochs as needed\n",
        "batch_size = 10\n",
        "\n",
        "# Define latent dimension\n",
        "latent_dim = 100\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(max_length, X_train_padded.shape[2]))\n",
        "x = Flatten()(encoder_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "x = Dense(256, activation='relu')(decoder_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "decoder_output = Dense(max_length * X_train_padded.shape[2], activation='linear')(x)\n",
        "decoder_output = Reshape((max_length, X_train_padded.shape[2]))(decoder_output)\n",
        "\n",
        "# Instantiate Encoder and Decoder models\n",
        "encoder = Model(encoder_input, [z_mean, z_log_var, z])\n",
        "decoder = Model(decoder_input, decoder_output)\n",
        "\n",
        "# VAE Model\n",
        "vae_output = decoder(z)\n",
        "vae = Model(encoder_input, vae_output)\n",
        "\n",
        "# Define VAE loss\n",
        "# Define VAE loss\n",
        "def vae_loss(x, x_decoded_mean, z_log_var=z_log_var, z_mean=z_mean):\n",
        "    reconstruction_loss = mse(K.flatten(x), K.flatten(x_decoded_mean))\n",
        "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return reconstruction_loss + kl_loss\n",
        "\n",
        "# Compile VAE\n",
        "vae.compile(optimizer=Adam(learning_rate=0.0002), loss=vae_loss)\n",
        "\n",
        "# Custom training loop\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}:')\n",
        "    for i in range(0, len(X_train_padded), batch_size):\n",
        "        X_train_batch = X_train_padded[i:i+batch_size]\n",
        "\n",
        "        # Perform a forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = encoder(X_train_batch)\n",
        "            x_decoded = decoder(z)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = vae_loss(X_train_batch, x_decoded, z_log_var, z_mean)\n",
        "\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss, vae.trainable_weights)\n",
        "\n",
        "        # Update weights\n",
        "        vae.optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    # Print progress after each epoch\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, VAE Loss: {loss.numpy()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIgNnRNhP8lx",
        "outputId": "398e1fa2-1e51-4855-e6a7-225f5791556f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100:\n",
            "Epoch 1/100, VAE Loss: [0.40388718 0.40361783 0.40430206 0.4040738  0.40384385 0.4046628\n",
            " 0.40412468 0.40449002 0.4045557  0.404346  ]\n",
            "Epoch 2/100:\n",
            "Epoch 2/100, VAE Loss: [0.2765308  0.27636918 0.27655396 0.2764894  0.27653793 0.27674457\n",
            " 0.27646613 0.27653882 0.27672955 0.27667856]\n",
            "Epoch 3/100:\n",
            "Epoch 3/100, VAE Loss: [0.215251   0.21519777 0.21525402 0.21523227 0.21521878 0.21535327\n",
            " 0.21527883 0.21530841 0.21533024 0.21528286]\n",
            "Epoch 4/100:\n",
            "Epoch 4/100, VAE Loss: [0.15921922 0.15925169 0.1592567  0.15925843 0.15922911 0.15920566\n",
            " 0.15924294 0.15925217 0.1592131  0.15922026]\n",
            "Epoch 5/100:\n",
            "Epoch 5/100, VAE Loss: [0.10588536 0.10588279 0.10588159 0.10588291 0.10588406 0.10588531\n",
            " 0.10588114 0.10588098 0.105886   0.10588646]\n",
            "Epoch 6/100:\n",
            "Epoch 6/100, VAE Loss: [0.04855942 0.04855993 0.0485578  0.04855762 0.04856092 0.04855419\n",
            " 0.04855935 0.04855689 0.04855318 0.04855546]\n",
            "Epoch 7/100:\n",
            "Epoch 7/100, VAE Loss: [0.01279282 0.01279313 0.01279205 0.01279197 0.0127936  0.01279016\n",
            " 0.01279275 0.01279155 0.01278968 0.01279085]\n",
            "Epoch 8/100:\n",
            "Epoch 8/100, VAE Loss: [0.01298179 0.012982   0.01298109 0.01298103 0.01298244 0.01297959\n",
            " 0.01298164 0.01298063 0.01297923 0.01298018]\n",
            "Epoch 9/100:\n",
            "Epoch 9/100, VAE Loss: [0.00666525 0.00666525 0.00666525 0.00666525 0.00666525 0.00666525\n",
            " 0.00666525 0.00666525 0.00666525 0.00666525]\n",
            "Epoch 10/100:\n",
            "Epoch 10/100, VAE Loss: [0.00929652 0.00929652 0.00929652 0.00929652 0.00929652 0.00929652\n",
            " 0.00929652 0.00929652 0.00929652 0.00929652]\n",
            "Epoch 11/100:\n",
            "Epoch 11/100, VAE Loss: [0.00592767 0.00592767 0.00592767 0.00592767 0.00592767 0.00592767\n",
            " 0.00592767 0.00592767 0.00592767 0.00592767]\n",
            "Epoch 12/100:\n",
            "Epoch 12/100, VAE Loss: [0.00345896 0.00345896 0.00345896 0.00345896 0.00345896 0.00345896\n",
            " 0.00345896 0.00345896 0.00345896 0.00345896]\n",
            "Epoch 13/100:\n",
            "Epoch 13/100, VAE Loss: [0.00387673 0.00387673 0.00387673 0.00387673 0.00387673 0.00387673\n",
            " 0.00387673 0.00387673 0.00387673 0.00387673]\n",
            "Epoch 14/100:\n",
            "Epoch 14/100, VAE Loss: [0.00420617 0.00420617 0.00420617 0.00420617 0.00420617 0.00420617\n",
            " 0.00420617 0.00420617 0.00420617 0.00420617]\n",
            "Epoch 15/100:\n",
            "Epoch 15/100, VAE Loss: [0.00509859 0.00509859 0.00509859 0.00509859 0.00509859 0.00509859\n",
            " 0.00509859 0.00509859 0.00509859 0.00509859]\n",
            "Epoch 16/100:\n",
            "Epoch 16/100, VAE Loss: [0.00298829 0.00298829 0.00298829 0.00298829 0.00298829 0.00298829\n",
            " 0.00298829 0.00298829 0.00298829 0.00298829]\n",
            "Epoch 17/100:\n",
            "Epoch 17/100, VAE Loss: [0.00442658 0.00442658 0.00442658 0.00442658 0.00442658 0.00442658\n",
            " 0.00442658 0.00442658 0.00442658 0.00442658]\n",
            "Epoch 18/100:\n",
            "Epoch 18/100, VAE Loss: [0.00466414 0.00466414 0.00466414 0.00466414 0.00466414 0.00466414\n",
            " 0.00466414 0.00466414 0.00466414 0.00466414]\n",
            "Epoch 19/100:\n",
            "Epoch 19/100, VAE Loss: [0.00446104 0.00446104 0.00446104 0.00446104 0.00446104 0.00446104\n",
            " 0.00446104 0.00446104 0.00446104 0.00446104]\n",
            "Epoch 20/100:\n",
            "Epoch 20/100, VAE Loss: [0.00247151 0.00247151 0.00247151 0.00247151 0.00247151 0.00247151\n",
            " 0.00247151 0.00247151 0.00247151 0.00247151]\n",
            "Epoch 21/100:\n",
            "Epoch 21/100, VAE Loss: [0.004249 0.004249 0.004249 0.004249 0.004249 0.004249 0.004249 0.004249\n",
            " 0.004249 0.004249]\n",
            "Epoch 22/100:\n",
            "Epoch 22/100, VAE Loss: [0.00436413 0.00436413 0.00436413 0.00436413 0.00436413 0.00436413\n",
            " 0.00436413 0.00436413 0.00436413 0.00436413]\n",
            "Epoch 23/100:\n",
            "Epoch 23/100, VAE Loss: [0.003687 0.003687 0.003687 0.003687 0.003687 0.003687 0.003687 0.003687\n",
            " 0.003687 0.003687]\n",
            "Epoch 24/100:\n",
            "Epoch 24/100, VAE Loss: [0.00289559 0.00289559 0.00289559 0.00289559 0.00289559 0.00289559\n",
            " 0.00289559 0.00289559 0.00289559 0.00289559]\n",
            "Epoch 25/100:\n",
            "Epoch 25/100, VAE Loss: [0.00277331 0.00277331 0.00277331 0.00277331 0.00277331 0.00277331\n",
            " 0.00277331 0.00277331 0.00277331 0.00277331]\n",
            "Epoch 26/100:\n",
            "Epoch 26/100, VAE Loss: [0.00270824 0.00270824 0.00270824 0.00270824 0.00270824 0.00270824\n",
            " 0.00270824 0.00270824 0.00270824 0.00270824]\n",
            "Epoch 27/100:\n",
            "Epoch 27/100, VAE Loss: [0.0029701 0.0029701 0.0029701 0.0029701 0.0029701 0.0029701 0.0029701\n",
            " 0.0029701 0.0029701 0.0029701]\n",
            "Epoch 28/100:\n",
            "Epoch 28/100, VAE Loss: [0.00443376 0.00443376 0.00443376 0.00443376 0.00443376 0.00443376\n",
            " 0.00443376 0.00443376 0.00443376 0.00443376]\n",
            "Epoch 29/100:\n",
            "Epoch 29/100, VAE Loss: [0.00439707 0.00439707 0.00439707 0.00439707 0.00439707 0.00439707\n",
            " 0.00439707 0.00439707 0.00439707 0.00439707]\n",
            "Epoch 30/100:\n",
            "Epoch 30/100, VAE Loss: [0.00645549 0.00645549 0.00645549 0.00645549 0.00645549 0.00645549\n",
            " 0.00645549 0.00645549 0.00645549 0.00645549]\n",
            "Epoch 31/100:\n",
            "Epoch 31/100, VAE Loss: [0.00350964 0.00350964 0.00350964 0.00350964 0.00350964 0.00350964\n",
            " 0.00350964 0.00350964 0.00350964 0.00350964]\n",
            "Epoch 32/100:\n",
            "Epoch 32/100, VAE Loss: [0.00343937 0.00343937 0.00343937 0.00343937 0.00343937 0.00343937\n",
            " 0.00343937 0.00343937 0.00343937 0.00343937]\n",
            "Epoch 33/100:\n",
            "Epoch 33/100, VAE Loss: [0.0027848 0.0027848 0.0027848 0.0027848 0.0027848 0.0027848 0.0027848\n",
            " 0.0027848 0.0027848 0.0027848]\n",
            "Epoch 34/100:\n",
            "Epoch 34/100, VAE Loss: [0.00255248 0.00255248 0.00255248 0.00255248 0.00255248 0.00255248\n",
            " 0.00255248 0.00255248 0.00255248 0.00255248]\n",
            "Epoch 35/100:\n",
            "Epoch 35/100, VAE Loss: [0.00248336 0.00248336 0.00248336 0.00248336 0.00248336 0.00248336\n",
            " 0.00248336 0.00248336 0.00248336 0.00248336]\n",
            "Epoch 36/100:\n",
            "Epoch 36/100, VAE Loss: [0.0016726 0.0016726 0.0016726 0.0016726 0.0016726 0.0016726 0.0016726\n",
            " 0.0016726 0.0016726 0.0016726]\n",
            "Epoch 37/100:\n",
            "Epoch 37/100, VAE Loss: [0.00399576 0.00399576 0.00399576 0.00399576 0.00399576 0.00399576\n",
            " 0.00399576 0.00399576 0.00399576 0.00399576]\n",
            "Epoch 38/100:\n",
            "Epoch 38/100, VAE Loss: [0.00507561 0.00507561 0.00507561 0.00507561 0.00507561 0.00507561\n",
            " 0.00507561 0.00507561 0.00507561 0.00507561]\n",
            "Epoch 39/100:\n",
            "Epoch 39/100, VAE Loss: [0.00296404 0.00296404 0.00296404 0.00296404 0.00296404 0.00296404\n",
            " 0.00296404 0.00296404 0.00296404 0.00296404]\n",
            "Epoch 40/100:\n",
            "Epoch 40/100, VAE Loss: [0.00263823 0.00263823 0.00263823 0.00263823 0.00263823 0.00263823\n",
            " 0.00263823 0.00263823 0.00263823 0.00263823]\n",
            "Epoch 41/100:\n",
            "Epoch 41/100, VAE Loss: [0.00551786 0.00551786 0.00551786 0.00551786 0.00551786 0.00551786\n",
            " 0.00551786 0.00551786 0.00551786 0.00551786]\n",
            "Epoch 42/100:\n",
            "Epoch 42/100, VAE Loss: [0.00754285 0.00754285 0.00754285 0.00754285 0.00754285 0.00754285\n",
            " 0.00754285 0.00754285 0.00754285 0.00754285]\n",
            "Epoch 43/100:\n",
            "Epoch 43/100, VAE Loss: [0.00145197 0.00145197 0.00145197 0.00145197 0.00145197 0.00145197\n",
            " 0.00145197 0.00145197 0.00145197 0.00145197]\n",
            "Epoch 44/100:\n",
            "Epoch 44/100, VAE Loss: [0.00301086 0.00301086 0.00301086 0.00301086 0.00301086 0.00301086\n",
            " 0.00301086 0.00301086 0.00301086 0.00301086]\n",
            "Epoch 45/100:\n",
            "Epoch 45/100, VAE Loss: [0.00393377 0.00393377 0.00393377 0.00393377 0.00393377 0.00393377\n",
            " 0.00393377 0.00393377 0.00393377 0.00393377]\n",
            "Epoch 46/100:\n",
            "Epoch 46/100, VAE Loss: [0.00289973 0.00289973 0.00289973 0.00289973 0.00289973 0.00289973\n",
            " 0.00289973 0.00289973 0.00289973 0.00289973]\n",
            "Epoch 47/100:\n",
            "Epoch 47/100, VAE Loss: [0.00357907 0.00357907 0.00357907 0.00357907 0.00357907 0.00357907\n",
            " 0.00357907 0.00357907 0.00357907 0.00357907]\n",
            "Epoch 48/100:\n",
            "Epoch 48/100, VAE Loss: [0.00158768 0.00158768 0.00158768 0.00158768 0.00158768 0.00158768\n",
            " 0.00158768 0.00158768 0.00158768 0.00158768]\n",
            "Epoch 49/100:\n",
            "Epoch 49/100, VAE Loss: [0.00373058 0.00373058 0.00373058 0.00373058 0.00373058 0.00373058\n",
            " 0.00373058 0.00373058 0.00373058 0.00373058]\n",
            "Epoch 50/100:\n",
            "Epoch 50/100, VAE Loss: [0.00417426 0.00417426 0.00417426 0.00417426 0.00417426 0.00417426\n",
            " 0.00417426 0.00417426 0.00417426 0.00417426]\n",
            "Epoch 51/100:\n",
            "Epoch 51/100, VAE Loss: [0.00356836 0.00356836 0.00356836 0.00356836 0.00356836 0.00356836\n",
            " 0.00356836 0.00356836 0.00356836 0.00356836]\n",
            "Epoch 52/100:\n",
            "Epoch 52/100, VAE Loss: [0.00503252 0.00503252 0.00503252 0.00503252 0.00503252 0.00503252\n",
            " 0.00503252 0.00503252 0.00503252 0.00503252]\n",
            "Epoch 53/100:\n",
            "Epoch 53/100, VAE Loss: [0.00265713 0.00265713 0.00265713 0.00265713 0.00265713 0.00265713\n",
            " 0.00265713 0.00265713 0.00265713 0.00265713]\n",
            "Epoch 54/100:\n",
            "Epoch 54/100, VAE Loss: [0.00143851 0.00143851 0.00143851 0.00143851 0.00143851 0.00143851\n",
            " 0.00143851 0.00143851 0.00143851 0.00143851]\n",
            "Epoch 55/100:\n",
            "Epoch 55/100, VAE Loss: [0.00132129 0.00132129 0.00132129 0.00132129 0.00132129 0.00132129\n",
            " 0.00132129 0.00132129 0.00132129 0.00132129]\n",
            "Epoch 56/100:\n",
            "Epoch 56/100, VAE Loss: [0.00286351 0.00286351 0.00286351 0.00286351 0.00286351 0.00286351\n",
            " 0.00286351 0.00286351 0.00286351 0.00286351]\n",
            "Epoch 57/100:\n",
            "Epoch 57/100, VAE Loss: [0.0035164 0.0035164 0.0035164 0.0035164 0.0035164 0.0035164 0.0035164\n",
            " 0.0035164 0.0035164 0.0035164]\n",
            "Epoch 58/100:\n",
            "Epoch 58/100, VAE Loss: [0.00169603 0.00169603 0.00169603 0.00169603 0.00169603 0.00169603\n",
            " 0.00169603 0.00169603 0.00169603 0.00169603]\n",
            "Epoch 59/100:\n",
            "Epoch 59/100, VAE Loss: [0.00468087 0.00468087 0.00468087 0.00468087 0.00468087 0.00468087\n",
            " 0.00468087 0.00468087 0.00468087 0.00468087]\n",
            "Epoch 60/100:\n",
            "Epoch 60/100, VAE Loss: [0.00332227 0.00332227 0.00332227 0.00332227 0.00332227 0.00332227\n",
            " 0.00332227 0.00332227 0.00332227 0.00332227]\n",
            "Epoch 61/100:\n",
            "Epoch 61/100, VAE Loss: [0.00286415 0.00286415 0.00286415 0.00286415 0.00286415 0.00286415\n",
            " 0.00286415 0.00286415 0.00286415 0.00286415]\n",
            "Epoch 62/100:\n",
            "Epoch 62/100, VAE Loss: [0.00255512 0.00255512 0.00255512 0.00255512 0.00255512 0.00255512\n",
            " 0.00255512 0.00255512 0.00255512 0.00255512]\n",
            "Epoch 63/100:\n",
            "Epoch 63/100, VAE Loss: [0.0014835 0.0014835 0.0014835 0.0014835 0.0014835 0.0014835 0.0014835\n",
            " 0.0014835 0.0014835 0.0014835]\n",
            "Epoch 64/100:\n",
            "Epoch 64/100, VAE Loss: [0.00329606 0.00329606 0.00329606 0.00329606 0.00329606 0.00329606\n",
            " 0.00329606 0.00329606 0.00329606 0.00329606]\n",
            "Epoch 65/100:\n",
            "Epoch 65/100, VAE Loss: [0.00357306 0.00357306 0.00357306 0.00357306 0.00357306 0.00357306\n",
            " 0.00357306 0.00357306 0.00357306 0.00357306]\n",
            "Epoch 66/100:\n",
            "Epoch 66/100, VAE Loss: [0.00190252 0.00190252 0.00190252 0.00190252 0.00190252 0.00190252\n",
            " 0.00190252 0.00190252 0.00190252 0.00190252]\n",
            "Epoch 67/100:\n",
            "Epoch 67/100, VAE Loss: [0.00197545 0.00197545 0.00197545 0.00197545 0.00197545 0.00197545\n",
            " 0.00197545 0.00197545 0.00197545 0.00197545]\n",
            "Epoch 68/100:\n",
            "Epoch 68/100, VAE Loss: [0.00214669 0.00214669 0.00214669 0.00214669 0.00214669 0.00214669\n",
            " 0.00214669 0.00214669 0.00214669 0.00214669]\n",
            "Epoch 69/100:\n",
            "Epoch 69/100, VAE Loss: [0.00510671 0.00510671 0.00510671 0.00510671 0.00510671 0.00510671\n",
            " 0.00510671 0.00510671 0.00510671 0.00510671]\n",
            "Epoch 70/100:\n",
            "Epoch 70/100, VAE Loss: [0.00351203 0.00351203 0.00351203 0.00351203 0.00351203 0.00351203\n",
            " 0.00351203 0.00351203 0.00351203 0.00351203]\n",
            "Epoch 71/100:\n",
            "Epoch 71/100, VAE Loss: [0.00258157 0.00258157 0.00258157 0.00258157 0.00258157 0.00258157\n",
            " 0.00258157 0.00258157 0.00258157 0.00258157]\n",
            "Epoch 72/100:\n",
            "Epoch 72/100, VAE Loss: [0.00338944 0.00338944 0.00338944 0.00338944 0.00338944 0.00338944\n",
            " 0.00338944 0.00338944 0.00338944 0.00338944]\n",
            "Epoch 73/100:\n",
            "Epoch 73/100, VAE Loss: [0.00236598 0.00236598 0.00236598 0.00236598 0.00236598 0.00236598\n",
            " 0.00236598 0.00236598 0.00236598 0.00236598]\n",
            "Epoch 74/100:\n",
            "Epoch 74/100, VAE Loss: [0.00188652 0.00188652 0.00188652 0.00188652 0.00188652 0.00188652\n",
            " 0.00188652 0.00188652 0.00188652 0.00188652]\n",
            "Epoch 75/100:\n",
            "Epoch 75/100, VAE Loss: [0.00412234 0.00412234 0.00412234 0.00412234 0.00412234 0.00412234\n",
            " 0.00412234 0.00412234 0.00412234 0.00412234]\n",
            "Epoch 76/100:\n",
            "Epoch 76/100, VAE Loss: [0.00282694 0.00282694 0.00282694 0.00282694 0.00282694 0.00282694\n",
            " 0.00282694 0.00282694 0.00282694 0.00282694]\n",
            "Epoch 77/100:\n",
            "Epoch 77/100, VAE Loss: [0.00312242 0.00312242 0.00312242 0.00312242 0.00312242 0.00312242\n",
            " 0.00312242 0.00312242 0.00312242 0.00312242]\n",
            "Epoch 78/100:\n",
            "Epoch 78/100, VAE Loss: [0.0041098 0.0041098 0.0041098 0.0041098 0.0041098 0.0041098 0.0041098\n",
            " 0.0041098 0.0041098 0.0041098]\n",
            "Epoch 79/100:\n",
            "Epoch 79/100, VAE Loss: [0.00245634 0.00245634 0.00245634 0.00245634 0.00245634 0.00245634\n",
            " 0.00245634 0.00245634 0.00245634 0.00245634]\n",
            "Epoch 80/100:\n",
            "Epoch 80/100, VAE Loss: [0.00405811 0.00405811 0.00405811 0.00405811 0.00405811 0.00405811\n",
            " 0.00405811 0.00405811 0.00405811 0.00405811]\n",
            "Epoch 81/100:\n",
            "Epoch 81/100, VAE Loss: [0.00295785 0.00295785 0.00295785 0.00295785 0.00295785 0.00295785\n",
            " 0.00295785 0.00295785 0.00295785 0.00295785]\n",
            "Epoch 82/100:\n",
            "Epoch 82/100, VAE Loss: [0.00299268 0.00299268 0.00299268 0.00299268 0.00299268 0.00299268\n",
            " 0.00299268 0.00299268 0.00299268 0.00299268]\n",
            "Epoch 83/100:\n",
            "Epoch 83/100, VAE Loss: [0.00309094 0.00309094 0.00309094 0.00309094 0.00309094 0.00309094\n",
            " 0.00309094 0.00309094 0.00309094 0.00309094]\n",
            "Epoch 84/100:\n",
            "Epoch 84/100, VAE Loss: [0.00242651 0.00242651 0.00242651 0.00242651 0.00242651 0.00242651\n",
            " 0.00242651 0.00242651 0.00242651 0.00242651]\n",
            "Epoch 85/100:\n",
            "Epoch 85/100, VAE Loss: [0.00212387 0.00212387 0.00212387 0.00212387 0.00212387 0.00212387\n",
            " 0.00212387 0.00212387 0.00212387 0.00212387]\n",
            "Epoch 86/100:\n",
            "Epoch 86/100, VAE Loss: [0.00210878 0.00210878 0.00210878 0.00210878 0.00210878 0.00210878\n",
            " 0.00210878 0.00210878 0.00210878 0.00210878]\n",
            "Epoch 87/100:\n",
            "Epoch 87/100, VAE Loss: [0.00202365 0.00202365 0.00202365 0.00202365 0.00202365 0.00202365\n",
            " 0.00202365 0.00202365 0.00202365 0.00202365]\n",
            "Epoch 88/100:\n",
            "Epoch 88/100, VAE Loss: [0.00187647 0.00187647 0.00187647 0.00187647 0.00187647 0.00187647\n",
            " 0.00187647 0.00187647 0.00187647 0.00187647]\n",
            "Epoch 89/100:\n",
            "Epoch 89/100, VAE Loss: [0.00111649 0.00111649 0.00111649 0.00111649 0.00111649 0.00111649\n",
            " 0.00111649 0.00111649 0.00111649 0.00111649]\n",
            "Epoch 90/100:\n",
            "Epoch 90/100, VAE Loss: [0.00452375 0.00452375 0.00452375 0.00452375 0.00452375 0.00452375\n",
            " 0.00452375 0.00452375 0.00452375 0.00452375]\n",
            "Epoch 91/100:\n",
            "Epoch 91/100, VAE Loss: [0.00213436 0.00213436 0.00213436 0.00213436 0.00213436 0.00213436\n",
            " 0.00213436 0.00213436 0.00213436 0.00213436]\n",
            "Epoch 92/100:\n",
            "Epoch 92/100, VAE Loss: [0.00241668 0.00241668 0.00241668 0.00241668 0.00241668 0.00241668\n",
            " 0.00241668 0.00241668 0.00241668 0.00241668]\n",
            "Epoch 93/100:\n",
            "Epoch 93/100, VAE Loss: [0.00285866 0.00285866 0.00285866 0.00285866 0.00285866 0.00285866\n",
            " 0.00285866 0.00285866 0.00285866 0.00285866]\n",
            "Epoch 94/100:\n",
            "Epoch 94/100, VAE Loss: [0.0024918 0.0024918 0.0024918 0.0024918 0.0024918 0.0024918 0.0024918\n",
            " 0.0024918 0.0024918 0.0024918]\n",
            "Epoch 95/100:\n",
            "Epoch 95/100, VAE Loss: [0.0032727 0.0032727 0.0032727 0.0032727 0.0032727 0.0032727 0.0032727\n",
            " 0.0032727 0.0032727 0.0032727]\n",
            "Epoch 96/100:\n",
            "Epoch 96/100, VAE Loss: [0.00131152 0.00131152 0.00131152 0.00131152 0.00131152 0.00131152\n",
            " 0.00131152 0.00131152 0.00131152 0.00131152]\n",
            "Epoch 97/100:\n",
            "Epoch 97/100, VAE Loss: [0.00158945 0.00158945 0.00158945 0.00158945 0.00158945 0.00158945\n",
            " 0.00158945 0.00158945 0.00158945 0.00158945]\n",
            "Epoch 98/100:\n",
            "Epoch 98/100, VAE Loss: [0.00371531 0.00371531 0.00371531 0.00371531 0.00371531 0.00371531\n",
            " 0.00371531 0.00371531 0.00371531 0.00371531]\n",
            "Epoch 99/100:\n",
            "Epoch 99/100, VAE Loss: [0.00349359 0.00349359 0.00349359 0.00349359 0.00349359 0.00349359\n",
            " 0.00349359 0.00349359 0.00349359 0.00349359]\n",
            "Epoch 100/100:\n",
            "Epoch 100/100, VAE Loss: [0.00172756 0.00172756 0.00172756 0.00172756 0.00172756 0.00172756\n",
            " 0.00172756 0.00172756 0.00172756 0.00172756]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import mse\n",
        "import numpy as np\n",
        "\n",
        "# Define or import processed_dataframes, X_train_list, y_train_list, max_length\n",
        "max_length = max(len(df) for df in processed_dataframes)\n",
        "\n",
        "# Reshape and pad the data\n",
        "X_train_padded = []\n",
        "for df in processed_dataframes:\n",
        "    df_padded = df.copy()\n",
        "    for col in df.columns:\n",
        "        df_padded[col] = np.pad(df[col].values, (0, max_length - len(df[col])), constant_values=0)\n",
        "    X_train_padded.append(df_padded[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']])\n",
        "\n",
        "X_train_padded = np.array([X.values for X in X_train_padded])\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "epochs = 100  # Change the number of epochs as needed\n",
        "batch_size = 10\n",
        "\n",
        "# Define latent dimension\n",
        "latent_dim = 100\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(max_length, X_train_padded.shape[2]))\n",
        "x = Flatten()(encoder_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "x = Dense(256, activation='relu')(decoder_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "decoder_output = Dense(max_length * X_train_padded.shape[2], activation='linear')(x)\n",
        "decoder_output = Reshape((max_length, X_train_padded.shape[2]))(decoder_output)\n",
        "\n",
        "# Instantiate Encoder and Decoder models\n",
        "encoder = Model(encoder_input, [z_mean, z_log_var, z])\n",
        "decoder = Model(decoder_input, decoder_output)\n",
        "\n",
        "# VAE Model\n",
        "vae_output = decoder(z)\n",
        "vae = Model(encoder_input, vae_output)\n",
        "\n",
        "# Define VAE loss\n",
        "def vae_loss(x, x_decoded_mean, z_log_var=z_log_var, z_mean=z_mean):\n",
        "    reconstruction_loss = mse(K.flatten(x), K.flatten(x_decoded_mean))\n",
        "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return reconstruction_loss + kl_loss\n",
        "\n",
        "# Compile VAE\n",
        "vae.compile(optimizer=Adam(learning_rate=0.0002), loss=vae_loss)\n",
        "\n",
        "# Custom training loop\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}:')\n",
        "    for df_idx in range(len(processed_dataframes)):\n",
        "        X_train_batch = np.expand_dims(X_train_padded[df_idx], axis=0)\n",
        "\n",
        "        # Perform a forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = encoder(X_train_batch)\n",
        "            x_decoded = decoder(z)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = vae_loss(X_train_batch, x_decoded, z_log_var, z_mean)\n",
        "\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss, vae.trainable_weights)\n",
        "\n",
        "        # Update weights\n",
        "        vae.optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    # Print progress after each epoch\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, VAE Loss: {loss.numpy()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsce4pzG3sUD",
        "outputId": "812c293c-2424-41fd-c206-ad08afc82047"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100:\n",
            "Epoch 1/100, VAE Loss: [0.01537677]\n",
            "Epoch 2/100:\n",
            "Epoch 2/100, VAE Loss: [0.004081]\n",
            "Epoch 3/100:\n",
            "Epoch 3/100, VAE Loss: [0.00719746]\n",
            "Epoch 4/100:\n",
            "Epoch 4/100, VAE Loss: [0.00328739]\n",
            "Epoch 5/100:\n",
            "Epoch 5/100, VAE Loss: [0.00155223]\n",
            "Epoch 6/100:\n",
            "Epoch 6/100, VAE Loss: [0.00198486]\n",
            "Epoch 7/100:\n",
            "Epoch 7/100, VAE Loss: [0.00758549]\n",
            "Epoch 8/100:\n",
            "Epoch 8/100, VAE Loss: [0.01460239]\n",
            "Epoch 9/100:\n",
            "Epoch 9/100, VAE Loss: [0.00094177]\n",
            "Epoch 10/100:\n",
            "Epoch 10/100, VAE Loss: [0.00410134]\n",
            "Epoch 11/100:\n",
            "Epoch 11/100, VAE Loss: [0.01943804]\n",
            "Epoch 12/100:\n",
            "Epoch 12/100, VAE Loss: [0.00089334]\n",
            "Epoch 13/100:\n",
            "Epoch 13/100, VAE Loss: [0.00372485]\n",
            "Epoch 14/100:\n",
            "Epoch 14/100, VAE Loss: [0.00079911]\n",
            "Epoch 15/100:\n",
            "Epoch 15/100, VAE Loss: [0.00252374]\n",
            "Epoch 16/100:\n",
            "Epoch 16/100, VAE Loss: [0.00250087]\n",
            "Epoch 17/100:\n",
            "Epoch 17/100, VAE Loss: [0.00104605]\n",
            "Epoch 18/100:\n",
            "Epoch 18/100, VAE Loss: [0.00070155]\n",
            "Epoch 19/100:\n",
            "Epoch 19/100, VAE Loss: [0.00295269]\n",
            "Epoch 20/100:\n",
            "Epoch 20/100, VAE Loss: [0.00537141]\n",
            "Epoch 21/100:\n",
            "Epoch 21/100, VAE Loss: [0.00332031]\n",
            "Epoch 22/100:\n",
            "Epoch 22/100, VAE Loss: [0.00318086]\n",
            "Epoch 23/100:\n",
            "Epoch 23/100, VAE Loss: [0.00120002]\n",
            "Epoch 24/100:\n",
            "Epoch 24/100, VAE Loss: [0.00241628]\n",
            "Epoch 25/100:\n",
            "Epoch 25/100, VAE Loss: [0.02597248]\n",
            "Epoch 26/100:\n",
            "Epoch 26/100, VAE Loss: [0.0043456]\n",
            "Epoch 27/100:\n",
            "Epoch 27/100, VAE Loss: [0.00050487]\n",
            "Epoch 28/100:\n",
            "Epoch 28/100, VAE Loss: [0.00079546]\n",
            "Epoch 29/100:\n",
            "Epoch 29/100, VAE Loss: [0.00602475]\n",
            "Epoch 30/100:\n",
            "Epoch 30/100, VAE Loss: [0.00196605]\n",
            "Epoch 31/100:\n",
            "Epoch 31/100, VAE Loss: [0.00086609]\n",
            "Epoch 32/100:\n",
            "Epoch 32/100, VAE Loss: [0.00169642]\n",
            "Epoch 33/100:\n",
            "Epoch 33/100, VAE Loss: [0.00055505]\n",
            "Epoch 34/100:\n",
            "Epoch 34/100, VAE Loss: [0.00413211]\n",
            "Epoch 35/100:\n",
            "Epoch 35/100, VAE Loss: [0.00096007]\n",
            "Epoch 36/100:\n",
            "Epoch 36/100, VAE Loss: [0.01023528]\n",
            "Epoch 37/100:\n",
            "Epoch 37/100, VAE Loss: [0.0007712]\n",
            "Epoch 38/100:\n",
            "Epoch 38/100, VAE Loss: [0.01121933]\n",
            "Epoch 39/100:\n",
            "Epoch 39/100, VAE Loss: [0.00038608]\n",
            "Epoch 40/100:\n",
            "Epoch 40/100, VAE Loss: [0.00203479]\n",
            "Epoch 41/100:\n",
            "Epoch 41/100, VAE Loss: [0.00033327]\n",
            "Epoch 42/100:\n",
            "Epoch 42/100, VAE Loss: [0.00128852]\n",
            "Epoch 43/100:\n",
            "Epoch 43/100, VAE Loss: [0.00069864]\n",
            "Epoch 44/100:\n",
            "Epoch 44/100, VAE Loss: [0.00280981]\n",
            "Epoch 45/100:\n",
            "Epoch 45/100, VAE Loss: [0.00126979]\n",
            "Epoch 46/100:\n",
            "Epoch 46/100, VAE Loss: [0.00403817]\n",
            "Epoch 47/100:\n",
            "Epoch 47/100, VAE Loss: [0.00635884]\n",
            "Epoch 48/100:\n",
            "Epoch 48/100, VAE Loss: [0.00222121]\n",
            "Epoch 49/100:\n",
            "Epoch 49/100, VAE Loss: [0.00109136]\n",
            "Epoch 50/100:\n",
            "Epoch 50/100, VAE Loss: [0.01163543]\n",
            "Epoch 51/100:\n",
            "Epoch 51/100, VAE Loss: [0.00050654]\n",
            "Epoch 52/100:\n",
            "Epoch 52/100, VAE Loss: [0.00110128]\n",
            "Epoch 53/100:\n",
            "Epoch 53/100, VAE Loss: [0.00054477]\n",
            "Epoch 54/100:\n",
            "Epoch 54/100, VAE Loss: [0.01403258]\n",
            "Epoch 55/100:\n",
            "Epoch 55/100, VAE Loss: [0.00122921]\n",
            "Epoch 56/100:\n",
            "Epoch 56/100, VAE Loss: [0.00103687]\n",
            "Epoch 57/100:\n",
            "Epoch 57/100, VAE Loss: [0.00065918]\n",
            "Epoch 58/100:\n",
            "Epoch 58/100, VAE Loss: [0.00044039]\n",
            "Epoch 59/100:\n",
            "Epoch 59/100, VAE Loss: [0.00251117]\n",
            "Epoch 60/100:\n",
            "Epoch 60/100, VAE Loss: [0.0031252]\n",
            "Epoch 61/100:\n",
            "Epoch 61/100, VAE Loss: [0.00230864]\n",
            "Epoch 62/100:\n",
            "Epoch 62/100, VAE Loss: [0.00073495]\n",
            "Epoch 63/100:\n",
            "Epoch 63/100, VAE Loss: [0.00132538]\n",
            "Epoch 64/100:\n",
            "Epoch 64/100, VAE Loss: [0.00092365]\n",
            "Epoch 65/100:\n",
            "Epoch 65/100, VAE Loss: [0.00025726]\n",
            "Epoch 66/100:\n",
            "Epoch 66/100, VAE Loss: [0.00037968]\n",
            "Epoch 67/100:\n",
            "Epoch 67/100, VAE Loss: [0.00121877]\n",
            "Epoch 68/100:\n",
            "Epoch 68/100, VAE Loss: [0.00034841]\n",
            "Epoch 69/100:\n",
            "Epoch 69/100, VAE Loss: [0.00729839]\n",
            "Epoch 70/100:\n",
            "Epoch 70/100, VAE Loss: [0.01183389]\n",
            "Epoch 71/100:\n",
            "Epoch 71/100, VAE Loss: [0.00181569]\n",
            "Epoch 72/100:\n",
            "Epoch 72/100, VAE Loss: [0.00101531]\n",
            "Epoch 73/100:\n",
            "Epoch 73/100, VAE Loss: [0.0008061]\n",
            "Epoch 74/100:\n",
            "Epoch 74/100, VAE Loss: [0.00095081]\n",
            "Epoch 75/100:\n",
            "Epoch 75/100, VAE Loss: [0.00081971]\n",
            "Epoch 76/100:\n",
            "Epoch 76/100, VAE Loss: [0.00648491]\n",
            "Epoch 77/100:\n",
            "Epoch 77/100, VAE Loss: [0.00051548]\n",
            "Epoch 78/100:\n",
            "Epoch 78/100, VAE Loss: [0.00292379]\n",
            "Epoch 79/100:\n",
            "Epoch 79/100, VAE Loss: [0.00204825]\n",
            "Epoch 80/100:\n",
            "Epoch 80/100, VAE Loss: [0.00396373]\n",
            "Epoch 81/100:\n",
            "Epoch 81/100, VAE Loss: [0.01656047]\n",
            "Epoch 82/100:\n",
            "Epoch 82/100, VAE Loss: [0.00462943]\n",
            "Epoch 83/100:\n",
            "Epoch 83/100, VAE Loss: [0.00637538]\n",
            "Epoch 84/100:\n",
            "Epoch 84/100, VAE Loss: [0.00620581]\n",
            "Epoch 85/100:\n",
            "Epoch 85/100, VAE Loss: [0.00271203]\n",
            "Epoch 86/100:\n",
            "Epoch 86/100, VAE Loss: [0.00020186]\n",
            "Epoch 87/100:\n",
            "Epoch 87/100, VAE Loss: [0.00949513]\n",
            "Epoch 88/100:\n",
            "Epoch 88/100, VAE Loss: [0.01816265]\n",
            "Epoch 89/100:\n",
            "Epoch 89/100, VAE Loss: [0.00252142]\n",
            "Epoch 90/100:\n",
            "Epoch 90/100, VAE Loss: [0.00098886]\n",
            "Epoch 91/100:\n",
            "Epoch 91/100, VAE Loss: [0.00113389]\n",
            "Epoch 92/100:\n",
            "Epoch 92/100, VAE Loss: [0.00081454]\n",
            "Epoch 93/100:\n",
            "Epoch 93/100, VAE Loss: [0.00517731]\n",
            "Epoch 94/100:\n",
            "Epoch 94/100, VAE Loss: [0.00238835]\n",
            "Epoch 95/100:\n",
            "Epoch 95/100, VAE Loss: [0.00394154]\n",
            "Epoch 96/100:\n",
            "Epoch 96/100, VAE Loss: [0.00184693]\n",
            "Epoch 97/100:\n",
            "Epoch 97/100, VAE Loss: [0.00160522]\n",
            "Epoch 98/100:\n",
            "Epoch 98/100, VAE Loss: [0.00099764]\n",
            "Epoch 99/100:\n",
            "Epoch 99/100, VAE Loss: [0.00548587]\n",
            "Epoch 100/100:\n",
            "Epoch 100/100, VAE Loss: [0.00170904]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oja40cW1iNbC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
        "import numpy as np\n",
        "\n",
        "X_train_list, X_val_list, y_train_list, y_val_list = train_test_split(\n",
        "    processed_dataframes, processed_dataframes, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "X_train = np.array([df[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']].values for df in X_train_list])\n",
        "y_train = np.array([df['output_sequence'].values for df in y_train_list])\n",
        "X_val = np.array([df[['mass_scaled', 'shell_thickness_scaled', 'y_coordinates_scaled']].values for df in X_val_list])\n",
        "y_val = np.array([df['output_sequence'].values for df in y_val_list])\n",
        "\n",
        "\n",
        "max_length = max(len(seq) for seq in y_train)\n",
        "\n",
        "\n",
        "X_train_padded = np.array([np.pad(X_seq, ((0, max_length - len(X_seq)), (0, 0)), constant_values=0) for X_seq in X_train])\n",
        "y_train_padded = np.array([np.pad(y_seq, (0, max_length - len(y_seq)), constant_values=0) for y_seq in y_train])\n",
        "X_val_padded = np.array([np.pad(X_seq, ((0, max_length - len(X_seq)), (0, 0)), constant_values=0) for X_seq in X_val])\n",
        "y_val_padded = np.array([np.pad(y_seq, (0, max_length - len(y_seq)), constant_values=0) for y_seq in y_val])\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(X_train_padded.shape[1], X_train_padded.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(16, return_sequences=False))\n",
        "model.add(RepeatVector(max_length))\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(500, activation='relu')))\n",
        "model.add(TimeDistributed(Dense(500, activation='relu')))\n",
        "model.add(TimeDistributed(Dense(X_train_padded.shape[2], activation='linear')))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "y_train_padded_reshaped = np.expand_dims(y_train_padded, axis=-1)\n",
        "y_val_padded_reshaped = np.expand_dims(y_val_padded, axis=-1)\n",
        "\n",
        "\n",
        "model.fit(X_train_padded, y_train_padded_reshaped, epochs=50, batch_size=10, validation_data=(X_val_padded, y_val_padded_reshaped))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}